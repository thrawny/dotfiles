editor = "cursor"
sandbox_mode = "workspace-write"
model = "gpt-5.2-codex"
model_reasoning_effort = "high"
tool_output_token_limit = 25000
# Leave room for native compaction near the 272–273k context window.
# Formula: 273000 - (tool_output_token_limit + 15000)
# With tool_output_token_limit=25000 ⇒ 273000 - (25000 + 15000) = 233000
model_auto_compact_token_limit = 233000
personality = "pragmatic"
suppress_unstable_features_warning = true
web_search = "live"

# Closest native match to the Claude powerline segments: model, context %, git branch.
[tui]
status_line = ["model-with-reasoning", "context-used", "git-branch"]

# [mcp_servers.context7]
# args = ["-y", "@upstash/context7-mcp"]
# command = "npx"
#
# [mcp_servers.nixos]
# command = "uvx"
# args = ["mcp-nixos"]

[features]
ghost_commit = false
unified_exec = true
apply_patch_freeform = true
skills = true
shell_snapshot = true
steer = true
voice_transcription = true

[sandbox_workspace_write]
writable_roots = [
  "/Users/jonas/Library/Caches",
  "/Users/jonas/.cache",
  "/Users/brew/Library/Caches",
  "/Users/jonas/.npm",
  "/Users/jonas/.matplotlib",
]
network_access = true

[projects."/Users/jonas/dotfiles"]
trust_level = "trusted"

[projects."/Users/jonas/code"]
trust_level = "trusted"

[profiles.clawdbot]
model = "gpt-5.2-codex"
reasoning = "medium"
